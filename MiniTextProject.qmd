---
title: "Mini Text Project"
sidebar: false
format:
  html: default
editor_options: 
  chunk_output_type: console
---


## Unifished framework of MP4


# Loading the Data from github broke the file is 160 mb and I think I overwhelmed the website, so this everything is eval = false right now

```{r}
library(tidyverse)
library(jsonlite)
library(tidytext)
library(textdata)
library(wordcloud)
library(ggthemes)
library(kableExtra)
```



```{r}
data <- read_json("https://github.com/leinstay/steamdb/raw/refs/heads/main/steamdb.json")


data2 <- as.data.frame(do.call(rbind, data))
 
 
 data2 <- data2 |> separate_wider_delim(published_store, delim = "-",
          names = c("publishedyear", "publishedmonth", "publishedday"), too_few = "debug")

```
 
 
```{r}

 data2 |> drop_na(publishedyear) |> 
   filter(publishedyear > 2006,
          publishedyear != "NULL") |>
   mutate(sequel = str_detect(name, "\\w* \\d\\d?\\b")) |> 
   group_by(publishedyear) |> 
   summarize("Number of Sequels" = sum(sequel),
            "Total Games" = n(),
            "Proportion are Sequels" = mean(sequel)) |> print(n=100) |>
   kable(digits=3) |>
   kable_styling(bootstrap_options = "striped", full_width = FALSE,
                 position = "float_right")

 data2 |>
  select(name, publishers) |>
  filter(str_detect(name, "^(..\\w*) +.* *\\1+$")) |>
  arrange(desc(publishers)) |>
  kable() |>
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "float_right")
 
 
 data2 |> select(name, full_price, meta_score) |> 
   mutate(words_in_name = str_count(name,"\\b[^ ]+\\b"),
          full_price = str_replace(full_price, "NULL", "0"),
          full_price = as.numeric(full_price),
          full_price = full_price/100) |>
   filter(full_price < 300) |>
   ggplot(aes(x = words_in_name, y = full_price)) + geom_point(alpha = .1) +
   geom_smooth(method = lm) +
   theme_clean()
   
 
pricedata <- data2 |> select(name, full_price) |> 
   mutate(words_in_name = str_count(name,"\\b[^ ]+\\b"),
          full_price = str_replace(full_price, "NULL", "0"),
          full_price = as.numeric(full_price),
          full_price = full_price/100) |>
   filter(full_price < 300)
  
summary(lm(full_price ~ words_in_name, data = pricedata))
 
 
 
 
 data2 |> select(languages, publishedyear, full_price) |>
   mutate(num_commas = str_count(languages,","),
          num_languages = num_commas + 1,
          publishedyear = as.numeric(publishedyear),
          full_price = str_replace(full_price, "NULL", "0"),
          full_price = as.numeric(full_price),
          full_price = full_price/100) |>
   filter(full_price == 59.99) |>
   group_by(publishedyear) |>
   summarize(avg_language = mean(num_languages)) |>
   filter(publishedyear > 2006) |>
   kable(digits = 1) |>
   kable_styling(bootstrap_options = "striped", full_width = FALSE,
                 position = "float_right")
 
 
  data2 |> 
   mutate(words_in_name = str_count(name,"\\b[^ ]+\\b"),
          num_commas = str_count(languages,","),
          num_languages = num_commas + 1,
          publishedyear = as.numeric(publishedyear),
          full_price = str_replace(full_price, "NULL", "0"),
          full_price = as.numeric(full_price),
          full_price = full_price/100) |>
   group_by(publishedyear) |>
   summarize(avg_words = mean(words_in_name)) |>
   filter(publishedyear > 2006) |>
   kable(digits = 1) |>
   kable_styling(bootstrap_options = "striped", full_width = FALSE,
                 position = "float_right")
 

```

 

```{r}

#the json data waas very broken, not sure if these count as strings and regular expressions for my 3, but basically i'm just tricking r into turning into proper text
 descriptions <- data2 |> 
   mutate(names = str_extract(name, ".*"),
          descriptions = str_extract(description, ".*")) |>
   select(descriptions, names, publishedyear)
 
 tidy_descriptions <- descriptions |>
  mutate(line = row_number()) |>
  unnest_tokens(word, descriptions, token = "words")
   
smart_stopwords <- get_stopwords(source = "smart")

font_stopwords <- tibble(
  word = c("br","li","strong","ul","quot", "game"), 
  lexicon = "font")


#top 20 words of all times
tidy_descriptions |>
   filter(publishedyear != "NULL") |>
  anti_join(smart_stopwords) |>
  anti_join(font_stopwords) |>
  count(word, sort = TRUE) |>
  filter(word != "NA") |>
  slice_max(n, n = 20) |>
  ggplot(aes(fct_reorder(word, n), n)) +
  geom_col() +
  coord_flip()

#top 10 word for each year (I tried so hard to order them for each year but it doesn't work )
tidy_descriptions |>
   filter(publishedyear != "NULL",
          publishedyear > 2006) |>
  anti_join(smart_stopwords) |>
  anti_join(font_stopwords) |>
  group_by(publishedyear, word) |>
  summarize(n =n()) |> 
  arrange(publishedyear, desc(n)) |>
  slice_max(n, n = 10) |> 
  ggplot(aes(fct_reorder(word, n), n, fill = publishedyear)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~ publishedyear, scales = "free")

```
 
```{r}

words <- tidy_descriptions |>
  anti_join(stop_words) |>
  anti_join(font_stopwords) |>
  count(word) |>
  filter(word != "NA") |>
  arrange(desc(n))

# word cloud of all years
wordcloud(
  words = words$word, 
  freq = words$n, 
  max.words = 200, 
  random.order = FALSE, 
  rot.per = 0.35,
  scale = c(3.5, 0.25),
  colors = brewer.pal(9, "Dark2"))



```




  


